{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddharth/miniconda3/envs/diffprep/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "from experiment.experiment_utils import set_random_seed, load_data, build_data, grid_search, makedir, save_result, load_data_multitask, load_data_multitask_synthetic_label\n",
    "from model import LogisticRegression\n",
    "from pipeline.diffprep_flex_pipeline import DiffPrepFlexPipeline\n",
    "from pipeline.diffprep_fix_pipeline import DiffPrepFixPipeline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from trainer.diffprep_trainer import DiffPrepSGD\n",
    "from utils import SummaryWriter\n",
    "from experiment.experiment_utils import min_max_normalize\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffPrepExperiment(object):\n",
    "    \"\"\"Run auto prep with one set of hyper parameters\"\"\"\n",
    "    def __init__(self, data_dir, dataset, prep_space, model_name, method, similarity_threshold):\n",
    "        self.data_dir = data_dir\n",
    "        self.dataset = dataset\n",
    "        self.prep_space = prep_space\n",
    "        self.model_name = model_name\n",
    "        self.method = method\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "\n",
    "    def run(self, params, verbose=True):        \n",
    "        X, y = load_data_multitask_synthetic_label(self.data_dir, self.dataset, similarity_threshold=self.similarity_threshold)\n",
    "        #X, y = load_data_multitask(self.data_dir, self.dataset)\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = build_data(X, y, random_state=params[\"split_seed\"])\n",
    "        \n",
    "        print(\"Dataset shapes: \", X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "        # pre norm for diffprep flex\n",
    "        if self.method == \"diffprep_flex\":\n",
    "            X_train, X_val, X_test = min_max_normalize(X_train, X_val, X_test)\n",
    "            params[\"patience\"] = 10\n",
    "            params[\"num_epochs\"] = 3000\n",
    "\n",
    "        # set random seed\n",
    "        set_random_seed(params)\n",
    "\n",
    "        ## transform pipeline\n",
    "        # define and fit first step\n",
    "        if self.method == \"diffprep_fix\":\n",
    "            prep_pipeline = DiffPrepFixPipeline(self.prep_space, temperature=params[\"temperature\"],\n",
    "                                             use_sample=params[\"sample\"],\n",
    "                                             diff_method=params[\"diff_method\"],\n",
    "                                             init_method=params[\"init_method\"])\n",
    "        elif self.method == \"diffprep_flex\":\n",
    "            prep_pipeline = DiffPrepFlexPipeline(self.prep_space, temperature=params[\"temperature\"],\n",
    "                            use_sample=params[\"sample\"],\n",
    "                            diff_method=params[\"diff_method\"],\n",
    "                            init_method=params[\"init_method\"])\n",
    "        else:\n",
    "            raise Exception(\"Wrong auto prep method\")\n",
    "\n",
    "        prep_pipeline.init_parameters(X_train, X_val, X_test)\n",
    "        print(\"Train size: ({}, {})\".format(X_train.shape[0], prep_pipeline.out_features))\n",
    "\n",
    "        # model\n",
    "        input_dim = prep_pipeline.out_features\n",
    "        output_dim = len(set(y.values.ravel()))\n",
    "\n",
    "        # model = TwoLayerNet(input_dim, output_dim)\n",
    "        set_random_seed(params)\n",
    "        if self.model_name == \"log\":\n",
    "            model = LogisticRegression(input_dim, output_dim)\n",
    "        else:\n",
    "            raise Exception(\"Wrong model\")\n",
    "\n",
    "        model = model.to(params[\"device\"])\n",
    "\n",
    "        # loss\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        # optimizer\n",
    "        model_optimizer = torch.optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=params[\"model_lr\"],\n",
    "            weight_decay=params[\"weight_decay\"],\n",
    "            momentum=params[\"momentum\"]\n",
    "        )\n",
    "        \n",
    "        if params[\"prep_lr\"] is None:\n",
    "            prep_lr = params[\"model_lr\"]\n",
    "        else:\n",
    "            prep_lr = params[\"prep_lr\"]\n",
    "    \n",
    "        prep_pipeline_optimizer = torch.optim.Adam(\n",
    "            prep_pipeline.parameters(),\n",
    "            lr=prep_lr,\n",
    "            betas=(0.5, 0.999),\n",
    "            weight_decay=params[\"weight_decay\"]\n",
    "        )\n",
    "\n",
    "        # scheduler\n",
    "        # model_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(model_optimizer, patience=patience, factor=0.1, threshold=0.001)\n",
    "        prep_pipeline_scheduler = None\n",
    "        model_scheduler = None\n",
    "\n",
    "        if params[\"logging\"]:\n",
    "            logger = SummaryWriter()\n",
    "        else:\n",
    "            logger = None\n",
    "\n",
    "        diff_prep = DiffPrepSGD(prep_pipeline, model, loss_fn, model_optimizer, prep_pipeline_optimizer,\n",
    "                    model_scheduler, prep_pipeline_scheduler, params, writer=logger)\n",
    "\n",
    "        result, best_model = diff_prep.fit(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "        return result, best_model, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8013333333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_df = pd.read_csv('./data/Airbnb/data.csv')\n",
    "airbnb_df\n",
    "y_rating = airbnb_df['Rating']\n",
    "\n",
    "X, y = load_data_multitask_synthetic_label(\"data\", \"Airbnb\", 0.8)\n",
    "(y == y_rating).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_diffprep(data_dir, dataset, result_dir, prep_space, params, model_name, method):\n",
    "    print(\"Dataset:\", dataset, \"Diff Method:\", params[\"diff_method\"], method)\n",
    "\n",
    "    diff_prep_exp = DiffPrepExperiment(data_dir, dataset, prep_space, model_name, method, similarity_threshold=params[\"similarity_threshold\"])\n",
    "    best_result, best_model, best_logger, best_params = grid_search(diff_prep_exp, deepcopy(params))\n",
    "    save_result(best_result, best_model, best_logger, best_params, result_dir, save_model=True)\n",
    "    print(\"DiffPrep Finished. val acc:\", best_result[\"best_val_acc\"], \"test acc\", best_result[\"best_test_acc\"])\n",
    "    return best_result, best_model, best_logger, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run diffprep_fix on dataset Airbnb\n",
      "Dataset: Airbnb Diff Method: num_diff diffprep_fix\n",
      "Model lr 0.01\n",
      "Dataset shapes:  (1800, 38) torch.Size([1800]) (600, 38) torch.Size([600]) (600, 38) torch.Size([600])\n",
      "Train size: (1800, 125)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1000/2000 [03:38<03:38,  4.58it/s, next_eval_time=22s, tr_loss=0.638, val_loss=0.644]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiffPrep Finished. val acc: 0.6816666666666666 test acc 0.6533333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from prep_space import space\n",
    "from experiment.baseline_experiment import run_baseline\n",
    "import os\n",
    "\n",
    "# define hyper parameters\n",
    "params = {\n",
    "    \"num_epochs\": 2000,\n",
    "    \"batch_size\": 512,\n",
    "    \"device\": \"cpu\",\n",
    "    #\"model_lr\": [0.1, 0.01, 0.001],\n",
    "    \"model_lr\": 0.01,\n",
    "    \"weight_decay\": 0,\n",
    "    \"model\": 'log',\n",
    "    \"train_seed\": 1,\n",
    "    \"split_seed\": 1,\n",
    "    \"method\": \"diffprep_fix\",\n",
    "    \"save_model\": True,\n",
    "    \"logging\": False,\n",
    "    \"no_crash\": False,\n",
    "    \"patience\": 3,\n",
    "    \"momentum\": 0.9,\n",
    "    \"similarity_threshold\": 0.1,\n",
    "}\n",
    "\n",
    "auto_prep_params = {\n",
    "    \"prep_lr\": None,\n",
    "    \"temperature\": 0.1,\n",
    "    \"grad_clip\": None,\n",
    "    \"pipeline_update_sample_size\": 512,\n",
    "    \"init_method\": \"default\",\n",
    "    \"diff_method\": \"num_diff\",\n",
    "    \"sample\": False\n",
    "}\n",
    "\n",
    "DATADIR = \"data\"\n",
    "\n",
    "params.update(auto_prep_params)\n",
    "\n",
    "datasets = sorted(os.listdir(DATADIR))\n",
    "dataset = \"Airbnb\"\n",
    "\n",
    "print(\"Run {} on dataset {}\".format(params[\"method\"], dataset))\n",
    "\n",
    "#result_dir = utils.makedir([\"result\", params[\"method\"], dataset, f'Rating_ground_truth'])\n",
    "result_dir = utils.makedir([\"result\", params[\"method\"], dataset, f'Rating_{params[\"similarity_threshold\"]}'])\n",
    "\n",
    "if params[\"method\"] in [\"diffprep_fix\", \"diffprep_flex\"]:\n",
    "    best_result, best_model, best_logger, best_params = run_diffprep(DATADIR, dataset, result_dir, space, params, params[\"model\"], params[\"method\"])\n",
    "else:\n",
    "    best_result, best_model, best_logger, best_params = run_baseline(DATADIR, dataset, result_dir, space, params, params[\"model\"], params[\"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = utils.makedir([\"result\", params[\"method\"], dataset, \"Price\"])\n",
    "save_result(best_result, best_model, best_logger, best_params, result_dir, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8374, 0.0096, 0.0085, 0.1348, 0.0096],\n",
       "        [0.8715, 0.0371, 0.0289, 0.0254, 0.0371],\n",
       "        [0.7386, 0.0354, 0.1491, 0.0415, 0.0354],\n",
       "        [0.7738, 0.0436, 0.0948, 0.0447, 0.0432],\n",
       "        [0.0299, 0.0043, 0.0085, 0.9518, 0.0054],\n",
       "        [0.5153, 0.1237, 0.1237, 0.1237, 0.1136],\n",
       "        [0.4854, 0.1222, 0.1222, 0.1222, 0.1481],\n",
       "        [0.5003, 0.1226, 0.1226, 0.1226, 0.1318],\n",
       "        [0.7513, 0.1847, 0.0214, 0.0214, 0.0212],\n",
       "        [0.4296, 0.1049, 0.1561, 0.1550, 0.1544],\n",
       "        [0.5054, 0.1255, 0.1255, 0.1255, 0.1181],\n",
       "        [0.6839, 0.0314, 0.0360, 0.2135, 0.0353],\n",
       "        [0.4776, 0.1208, 0.1208, 0.1208, 0.1599],\n",
       "        [0.4930, 0.1267, 0.1267, 0.1267, 0.1267],\n",
       "        [0.5261, 0.1272, 0.1272, 0.1272, 0.0924],\n",
       "        [0.5077, 0.1230, 0.1230, 0.1230, 0.1232],\n",
       "        [0.5151, 0.1274, 0.1274, 0.1274, 0.1027],\n",
       "        [0.6530, 0.0548, 0.0548, 0.1910, 0.0465],\n",
       "        [0.5609, 0.1281, 0.0205, 0.1114, 0.1791],\n",
       "        [0.2549, 0.0697, 0.1932, 0.2905, 0.1918],\n",
       "        [0.0583, 0.0179, 0.2342, 0.6689, 0.0206],\n",
       "        [0.3102, 0.0797, 0.2868, 0.2412, 0.0822],\n",
       "        [0.4285, 0.1072, 0.1823, 0.1747, 0.1074],\n",
       "        [0.5990, 0.1533, 0.1583, 0.0441, 0.0452],\n",
       "        [0.6894, 0.2100, 0.0309, 0.0458, 0.0239],\n",
       "        [0.5237, 0.1267, 0.1202, 0.1107, 0.1188],\n",
       "        [0.4129, 0.0994, 0.1066, 0.0969, 0.2842],\n",
       "        [0.6223, 0.1561, 0.0739, 0.0740, 0.0738],\n",
       "        [0.4924, 0.1245, 0.1245, 0.1245, 0.1342],\n",
       "        [0.4128, 0.1049, 0.1867, 0.1048, 0.1908],\n",
       "        [0.5076, 0.1268, 0.1268, 0.1268, 0.1122],\n",
       "        [0.4982, 0.1228, 0.1228, 0.1228, 0.1334],\n",
       "        [0.4876, 0.1223, 0.1223, 0.1223, 0.1454],\n",
       "        [0.4789, 0.1208, 0.1208, 0.1208, 0.1587],\n",
       "        [0.5017, 0.1244, 0.1244, 0.1244, 0.1252],\n",
       "        [0.5115, 0.1275, 0.1275, 0.1275, 0.1061],\n",
       "        [0.5166, 0.1274, 0.1274, 0.1274, 0.1011]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(best_model['prep_pipeline']['pipeline.0.num_tf_prob_logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 6, 6, 6, 6, 5, 2, 6, 5, 5, 6, 2, 6, 5, 5, 6, 2, 6, 1, 6, 6,\n",
       "       6, 6, 6, 1, 6, 6, 5, 6, 6, 6, 2, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 0, 2, 6, 6, 6, 6, 0, 6, 6, 2, 6, 6, 2, 6, 6, 2, 6,\n",
       "       6, 6, 6, 6, 6, 6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(best_model['prep_pipeline']['pipeline.3.tf_prob_logits']).numpy().argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha torch.Size([94, 3, 3])\n",
      "pipeline.0.num_tf_prob_logits torch.Size([37, 5])\n",
      "pipeline.0.cat_tf_prob_logits torch.Size([57, 2])\n",
      "pipeline.1.tf_prob_logits torch.Size([94, 4])\n",
      "pipeline.2.tf_prob_logits torch.Size([94, 10])\n",
      "pipeline.3.tf_prob_logits torch.Size([94, 7])\n",
      "pipeline.4.tf_prob_logits torch.Size([94, 4])\n",
      "pipeline.5.tf_prob_logits torch.Size([94, 10])\n",
      "pipeline.6.tf_prob_logits torch.Size([94, 7])\n",
      "pipeline.7.tf_prob_logits torch.Size([94, 4])\n",
      "pipeline.8.tf_prob_logits torch.Size([94, 10])\n",
      "pipeline.9.tf_prob_logits torch.Size([94, 7])\n"
     ]
    }
   ],
   "source": [
    "# rating\n",
    "for md in best_model['prep_pipeline'].keys():\n",
    "    print(md, best_model['prep_pipeline'][md].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha torch.Size([94, 3, 3])\n",
      "pipeline.0.num_tf_prob_logits torch.Size([37, 5])\n",
      "pipeline.0.cat_tf_prob_logits torch.Size([57, 2])\n",
      "pipeline.1.tf_prob_logits torch.Size([94, 4])\n",
      "pipeline.2.tf_prob_logits torch.Size([94, 10])\n",
      "pipeline.3.tf_prob_logits torch.Size([94, 7])\n",
      "pipeline.4.tf_prob_logits torch.Size([94, 4])\n",
      "pipeline.5.tf_prob_logits torch.Size([94, 10])\n",
      "pipeline.6.tf_prob_logits torch.Size([94, 7])\n",
      "pipeline.7.tf_prob_logits torch.Size([94, 4])\n",
      "pipeline.8.tf_prob_logits torch.Size([94, 10])\n",
      "pipeline.9.tf_prob_logits torch.Size([94, 7])\n"
     ]
    }
   ],
   "source": [
    "# price\n",
    "for md in best_model['prep_pipeline'].keys():\n",
    "    print(md, best_model['prep_pipeline'][md].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps:\n",
    "\n",
    "1. Load the transfer datasets\n",
    "2. Train using diffprep fix on one task\n",
    "3. Create a new diffprep fix pipeline where the pipeline is set to the one we got above, and is frozen\n",
    "4. Train the same model arch on the new task, and see accuracy etc.\n",
    "5. Train the same model arch on the new task with a fresh diffprep pipeline, and see accuracy etc.\n",
    "6. Compared the tau matrices and the operatiosn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffprep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
