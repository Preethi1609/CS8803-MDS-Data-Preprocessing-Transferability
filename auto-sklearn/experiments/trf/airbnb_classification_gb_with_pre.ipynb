{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Classification\n",
        "\n",
        "The following example shows how to fit a simple classification model with\n",
        "*auto-sklearn*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "import sklearn.metrics\n",
        "import autosklearn.classification\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import autosklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23202\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# file_path = '../data/titanic_dirty_data.csv'\n",
        "file_path = '../data/airbnb.csv'\n",
        "\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(len(df))\n",
        "\n",
        "# df = df.dropna(subset=['Survived'])\n",
        "# y = df['Survived']\n",
        "# X = df.drop('Survived', axis=1)\n",
        "\n",
        "df = df.dropna(subset=['Rating'])\n",
        "y = df['Rating']\n",
        "X = df.drop('Rating', axis=1)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build and fit a classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitting to the training data:   0%|\u001b[32m          \u001b[0m| 0/120 [00:00<?, ?it/s, The total time budget for this task is 0:02:00]/home/preethi/projects/hitlda-project/auto-sklearn/autosklearn/data/feature_validator.py:298: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if is_sparse(X[column]):\n",
            "/home/preethi/projects/hitlda-project/auto-sklearn/autosklearn/data/feature_validator.py:318: UserWarning: Input Column LocationName has generic type object. Autosklearn will treat this column as string. Please ensure that this setting is suitable for your task.\n",
            "  warnings.warn(\n",
            "Fitting to the training data:  15%|\u001b[32m█▌        \u001b[0m| 18/120 [00:18<01:42,  1.00s/it, The total time budget for this task is 0:02:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARNING] [2023-12-03 13:07:30,689:Client-EnsembleBuilder] No runs were available to build an ensemble from\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitting to the training data:  18%|\u001b[32m█▊        \u001b[0m| 21/120 [00:21<01:39,  1.00s/it, The total time budget for this task is 0:02:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARNING] [2023-12-03 13:07:33,033:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
            "[WARNING] [2023-12-03 13:07:33,769:Client-EnsembleBuilder] No runs were available to build an ensemble from\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitting to the training data:  18%|\u001b[32m█▊        \u001b[0m| 22/120 [00:22<01:38,  1.00s/it, The total time budget for this task is 0:02:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARNING] [2023-12-03 13:07:34,437:Client-EnsembleBuilder] No runs were available to build an ensemble from\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitting to the training data:  28%|\u001b[32m██▊       \u001b[0m| 33/120 [00:33<01:27,  1.00s/it, The total time budget for this task is 0:02:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARNING] [2023-12-03 13:07:45,513:Client-EnsembleBuilder] No runs were available to build an ensemble from\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitting to the training data:  30%|\u001b[32m███       \u001b[0m| 36/120 [00:36<01:24,  1.00s/it, The total time budget for this task is 0:02:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARNING] [2023-12-03 13:07:47,938:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
            "[WARNING] [2023-12-03 13:07:48,621:Client-EnsembleBuilder] No runs were available to build an ensemble from\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitting to the training data:  31%|\u001b[32m███       \u001b[0m| 37/120 [00:37<01:23,  1.00s/it, The total time budget for this task is 0:02:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARNING] [2023-12-03 13:07:49,251:Client-EnsembleBuilder] No runs were available to build an ensemble from\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitting to the training data:  32%|\u001b[32m███▏      \u001b[0m| 38/120 [00:38<01:22,  1.00s/it, The total time budget for this task is 0:02:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARNING] [2023-12-03 13:07:49,945:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
            "[WARNING] [2023-12-03 13:07:50,708:Client-EnsembleBuilder] No runs were available to build an ensemble from\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitting to the training data: 100%|\u001b[32m██████████\u001b[0m| 120/120 [01:50<00:00,  1.09it/s, The total time budget for this task is 0:02:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration(values={\n",
            "  'balancing:strategy': 'none',\n",
            "  'classifier:__choice__': 'gradient_boosting',\n",
            "  'classifier:gradient_boosting:early_stop': 'off',\n",
            "  'classifier:gradient_boosting:l2_regularization': 1e-10,\n",
            "  'classifier:gradient_boosting:learning_rate': 0.1,\n",
            "  'classifier:gradient_boosting:loss': 'auto',\n",
            "  'classifier:gradient_boosting:max_bins': 255,\n",
            "  'classifier:gradient_boosting:max_depth': 'None',\n",
            "  'classifier:gradient_boosting:max_leaf_nodes': 31,\n",
            "  'classifier:gradient_boosting:min_samples_leaf': 20,\n",
            "  'classifier:gradient_boosting:scoring': 'loss',\n",
            "  'classifier:gradient_boosting:tol': 1e-07,\n",
            "  'data_preprocessor:__choice__': 'feature_type',\n",
            "  'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'mean',\n",
            "  'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'standardize',\n",
            "  'data_preprocessor:feature_type:text_transformer:text_encoding:__choice__': 'tfidf_encoding',\n",
            "  'data_preprocessor:feature_type:text_transformer:text_encoding:tfidf_encoding:analyzer': 'char',\n",
            "  'data_preprocessor:feature_type:text_transformer:text_encoding:tfidf_encoding:binary': 'False',\n",
            "  'data_preprocessor:feature_type:text_transformer:text_encoding:tfidf_encoding:max_df': 1.0,\n",
            "  'data_preprocessor:feature_type:text_transformer:text_encoding:tfidf_encoding:min_df': 0.0,\n",
            "  'data_preprocessor:feature_type:text_transformer:text_encoding:tfidf_encoding:ngram_range_char': 4,\n",
            "  'data_preprocessor:feature_type:text_transformer:text_encoding:tfidf_encoding:norm': 'l2',\n",
            "  'data_preprocessor:feature_type:text_transformer:text_encoding:tfidf_encoding:per_column': False,\n",
            "  'data_preprocessor:feature_type:text_transformer:text_encoding:tfidf_encoding:sublinear_tf': 'False',\n",
            "  'data_preprocessor:feature_type:text_transformer:text_feature_reduction:n_components': 100,\n",
            "  'feature_preprocessor:__choice__': 'no_preprocessing',\n",
            "})\n",
            "\n"
          ]
        }
      ],
      "source": [
        "automl = autosklearn.classification.AutoSklearnClassifier(\n",
        "    time_left_for_this_task=120,\n",
        "    per_run_time_limit=10,\n",
        "    include = {\n",
        "        'classifier': [\"gradient_boosting\"],\n",
        "    },\n",
        "    tmp_folder=\"tmp/autosklearn_classification_example_tmp5\",\n",
        ")\n",
        "\n",
        "automl.fit(X_train, y_train)\n",
        "run_key = list(automl.automl_.runhistory_.data.keys())[0]\n",
        "run_value = automl.automl_.runhistory_.data[run_key]\n",
        "config=automl.automl_.runhistory_.ids_config[run_key.config_id]\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View the models found by auto-sklearn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          rank  ensemble_weight               type      cost  duration\n",
            "model_id                                                              \n",
            "12           1             0.84  gradient_boosting  0.300849  7.471197\n",
            "18           2             0.16  gradient_boosting  0.304603  9.523919\n"
          ]
        }
      ],
      "source": [
        "print(automl.leaderboard())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Print the final ensemble constructed by auto-sklearn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{   12: {   'balancing': Balancing(random_state=1),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f354c038b50>,\n",
            "            'cost': 0.3008488410055501,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f35473235e0>,\n",
            "            'ensemble_weight': 0.84,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f354c0385e0>,\n",
            "            'model_id': 12,\n",
            "            'rank': 1,\n",
            "            'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
            "                               l2_regularization=3.609412172481434e-10,\n",
            "                               learning_rate=0.05972079854295879, max_iter=512,\n",
            "                               max_leaf_nodes=4, min_samples_leaf=2,\n",
            "                               n_iter_no_change=14, random_state=1,\n",
            "                               validation_fraction=None, warm_start=True)},\n",
            "    18: {   'balancing': Balancing(random_state=1),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f3546ea25b0>,\n",
            "            'cost': 0.3046033300685602,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f354c0b87f0>,\n",
            "            'ensemble_weight': 0.16,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f3546ea2490>,\n",
            "            'model_id': 18,\n",
            "            'rank': 2,\n",
            "            'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
            "                               l2_regularization=0.005326508887463406,\n",
            "                               learning_rate=0.060800813211425456, max_iter=512,\n",
            "                               max_leaf_nodes=6, min_samples_leaf=5,\n",
            "                               n_iter_no_change=5, random_state=1,\n",
            "                               validation_fraction=None, warm_start=True)}}\n"
          ]
        }
      ],
      "source": [
        "pprint(automl.show_models(), indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get the Score of the final ensemble\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/preethi/projects/hitlda-project/auto-sklearn/py39/lib/python3.9/site-packages/sklearn/utils/validation.py:571: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  array.dtypes.apply(is_sparse).any()):\n",
            "/home/preethi/projects/hitlda-project/auto-sklearn/py39/lib/python3.9/site-packages/sklearn/utils/validation.py:571: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  array.dtypes.apply(is_sparse).any()):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Y', 'N'}\n",
            "{'Y', 'N'}\n",
            "Accuracy score: 0.6901529842706313\n",
            "Precision 0.7097013083189336\n",
            "Recall 0.9164807140580172\n"
          ]
        }
      ],
      "source": [
        "predictions = automl.predict(X_test)\n",
        "print(set(predictions))\n",
        "print(set(y_test))\n",
        "print(\"Accuracy score:\", sklearn.metrics.accuracy_score(y_test, predictions))\n",
        "print(\"Precision\", sklearn.metrics.precision_score(y_test, predictions,pos_label='Y'))\n",
        "print(\"Recall\", sklearn.metrics.recall_score(y_test, predictions,pos_label='Y'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/preethi/projects/hitlda-project/auto-sklearn/py39/lib/python3.9/site-packages/sklearn/utils/validation.py:571: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  array.dtypes.apply(is_sparse).any()):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "138\n",
            "[  6   5   7   4   3   2   1   0  33   8  35  29  12  13  30  31  15  22\n",
            "  32  34  10  24  16  19  27  20  25  37  36  21  11  23  26  17   9  28\n",
            "  18  14 116  84 102 135 136 130  72  74 137 129 118  87 132  73  64 133\n",
            "  94 126 122  90  75  43 131 125 107 134 128 110 117 121  93  78  97 113\n",
            "  58  55  98 127  68  57  59 100 111 123  40  54 120 124 109 106  86  99\n",
            "  85  82  38 108  77  92  91 119 112  51  88  47  39  62  81  48 115  66\n",
            "  53 101 114  61 103 105  49  45  44  96 104  50  41  52  69  63  56  42\n",
            "  80  70  95  79  60  46  71  89  83  76  67  65]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# file_path = '../data/clean_titanic_data_rf.csv'\n",
        "file_path = '../data/clean_airbnb_data_gb.csv'\n",
        "\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# df = df.dropna(subset=['Survived'])\n",
        "# y = df['Survived']\n",
        "# X = df.drop('Survived', axis=1)\n",
        "\n",
        "df = df.dropna(subset=['Rating'])\n",
        "y = df['Rating']\n",
        "X = df.drop('Rating', axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
        "\n",
        "feature_names = [f\"feature {i}\" for i in range(X.shape[1])]\n",
        "forest = RandomForestClassifier(random_state=0)\n",
        "forest.fit(X_train, y_train)\n",
        "\n",
        "importances = forest.feature_importances_\n",
        "print(len(importances))\n",
        "sorted_indices = np.argsort(importances)[::-1]\n",
        "print(sorted_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0.0, 1.0}\n",
            "{0.0, 1.0}\n",
            "Accuracy score: 0.7239819004524887\n",
            "Precision 0.7612273361227336\n",
            "Recall 0.8652504755865568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/preethi/projects/hitlda-project/auto-sklearn/py39/lib/python3.9/site-packages/sklearn/utils/validation.py:571: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  array.dtypes.apply(is_sparse).any()):\n"
          ]
        }
      ],
      "source": [
        "rf_predictions = forest.predict(X_test)\n",
        "print(set(rf_predictions))\n",
        "print(set(y_test))\n",
        "print(\"Accuracy score:\", sklearn.metrics.accuracy_score(y_test, rf_predictions))\n",
        "print(\"Precision\", sklearn.metrics.precision_score(y_test, rf_predictions))\n",
        "print(\"Recall\", sklearn.metrics.recall_score(y_test, rf_predictions))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
